# train.py
import matplotlib.pyplot as plt
import torch
from torch.utils.data import DataLoader
from torchvision import transforms
from torchvision.datasets import MNIST

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.family'] = 'SimHei'

# å®šä¹‰ç¥ç»ç½‘ç»œç»“æ„
class Net(torch.nn.Module):
    def __init__(self):
        super().__init__()
        # è¾“å…¥å±‚ -> ç¬¬ä¸€éšè—å±‚
        self.fc1 = torch.nn.Linear(28*28, 128)
        # ç¬¬ä¸€éšè—å±‚ -> ç¬¬äºŒéšè—å±‚
        self.fc2 = torch.nn.Linear(128, 128)
        # ç¬¬äºŒéšè—å±‚ -> ç¬¬ä¸‰éšè—å±‚
        self.fc3 = torch.nn.Linear(128, 64)
        # ç¬¬ä¸‰éšè—å±‚ -> è¾“å‡ºå±‚
        self.fc4 = torch.nn.Linear(64, 10)

    def forward(self, x):
        x = x.view(-1, 28*28)
        x = torch.relu(self.fc1(x))
        x = torch.relu(self.fc2(x))
        x = torch.relu(self.fc3(x))
        x = torch.nn.functional.log_softmax(self.fc4(x), dim=1)
        return x

# æ•°æ®åŠ è½½å‡½æ•°
def get_data_loader(is_train, batch_size=64):
    to_tensor = transforms.Compose([transforms.ToTensor()])
    data_set = MNIST(
        root="", train=is_train, transform=to_tensor, download=True
    )
    return DataLoader(data_set, batch_size=batch_size, shuffle=True)

# æ¨¡å‹è¯„ä¼°å‡½æ•°
def evaluate(test_data, net, device):
    net.eval()
    n_correct, n_total = 0, 0
    with torch.no_grad():
        for x, y in test_data:
            x, y = x.to(device), y.to(device)
            output = net(x.view(-1, 28*28))
            pred = torch.argmax(output, dim=1)
            n_correct += (pred == y).sum().item()
            n_total += y.size(0)
    return n_correct / n_total

def main():
    print("ğŸ“¥ æ­£åœ¨åŠ è½½ MNIST æ•°æ®é›† ...")
    train_data = get_data_loader(is_train=True)
    test_data = get_data_loader(is_train=False)
    print("âœ… æ•°æ®åŠ è½½å®Œæˆï¼")

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    net = Net().to(device)

    print(f"ğŸ” åˆå§‹æ¨¡å‹å‡†ç¡®ç‡: {evaluate(test_data, net, device)*100:.2f}%")

    optimizer = torch.optim.Adam(net.parameters(), lr=0.001)
    num_epochs = 15
    print("ğŸš€ å¼€å§‹è®­ç»ƒæ¨¡å‹ ...")

    for epoch in range(num_epochs):
        net.train()
        for batch_idx, (x, y) in enumerate(train_data, start=1):
            x, y = x.to(device), y.to(device)
            optimizer.zero_grad()
            output = net(x.view(-1, 28*28))
            loss = torch.nn.functional.nll_loss(output, y)
            loss.backward()
            optimizer.step()

            if batch_idx % 100 == 0:
                print(f"ğŸ“Š [ç¬¬{epoch+1}è½® | æ‰¹æ¬¡ {batch_idx}] å½“å‰æŸå¤±: {loss.item():.4f}")

        acc = evaluate(test_data, net, device)
        print(f"âœ… ç¬¬ {epoch+1} è½®è®­ç»ƒç»“æŸï¼Œæµ‹è¯•é›†å‡†ç¡®ç‡: {acc*100:.2f}%")

    torch.save(net.state_dict(), "mnist_net.pth")
    print("âœ… æ¨¡å‹å·²ä¿å­˜ä¸º mnist_net.pth")

    # å±•ç¤ºå‰4å¼ æµ‹è¯•é›†æ ·æœ¬åŠé¢„æµ‹ç»“æœ
    print("\nğŸ“¸ å±•ç¤ºæµ‹è¯•é›†æ ·æœ¬é¢„æµ‹ç»“æœ:")
    for n, (x, y) in enumerate(test_data):
        if n > 3:
            break
        x0 = x[0].to(device)
        predict = torch.argmax(net(x0.view(-1, 28*28))).item()
        plt.figure(n)
        plt.imshow(x[0].view(28,28), cmap="gray")
        plt.title(f"é¢„æµ‹ç»“æœ: {predict} | å®é™…æ ‡ç­¾: {y[0].item()}")
    plt.show()
    print("ğŸ‰ è®­ç»ƒå®Œæˆï¼")

if __name__ == "__main__":
    main()
